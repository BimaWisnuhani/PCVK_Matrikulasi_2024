{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1obYyr_j6CPBSkK8WXr0ol49LdOmJJhpR",
      "authorship_tag": "ABX9TyPxrMM9efRegxalxR95c3Xj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BimaWisnuhani/PCVK_Matrikulasi_2024/blob/main/PCVK_Bima_Wisnuhani.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbGrg92pserJ",
        "outputId": "7c12651b-167c-4e30-9f9d-b620c9822230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "!pip install supervision\n",
        "\n",
        "!yolo task=detect mode=train model=yolov8n.pt data=coco128.yaml epochs=1 imgsz=640"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WT86abVqtqd",
        "outputId": "40bac634-55e8-408b-d284-476828fc9d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.20)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: supervision in /usr/local/lib/python3.10/dist-packages (0.24.0)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.23.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from supervision) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.10/dist-packages (from supervision) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (6.0.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\n",
            "Ultralytics 8.3.20 泅 Python-3.10.12 torch-2.4.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco128.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<00:00, 842.64it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco128/labels/train2017.cache\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added 笨\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        1/1         0G       1.13      1.474      1.261        196        640: 100% 8/8 [02:26<00:00, 18.35s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:47<00:00, 11.92s/it]\n",
            "                   all        128        929      0.656      0.524      0.614      0.455\n",
            "\n",
            "1 epochs completed in 0.059 hours.\n",
            "Optimizer stripped from runs/detect/train3/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from runs/detect/train3/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating runs/detect/train3/weights/best.pt...\n",
            "Ultralytics 8.3.20 泅 Python-3.10.12 torch-2.4.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:37<00:00,  9.35s/it]\n",
            "                   all        128        929      0.657      0.524      0.614      0.455\n",
            "                person         61        254      0.817      0.673      0.765      0.539\n",
            "               bicycle          3          6       0.59      0.333      0.317      0.277\n",
            "                   car         12         46      0.923      0.217      0.276      0.169\n",
            "            motorcycle          4          5      0.677      0.844      0.881      0.675\n",
            "              airplane          5          6      0.822      0.776      0.927      0.675\n",
            "                   bus          5          7      0.591      0.714      0.728       0.67\n",
            "                 train          3          3      0.547      0.667      0.694      0.589\n",
            "                 truck          5         12          1      0.323      0.487      0.304\n",
            "                  boat          2          6      0.271      0.167      0.374       0.25\n",
            "         traffic light          4         14      0.734      0.201      0.201      0.138\n",
            "             stop sign          2          2          1      0.967      0.995      0.702\n",
            "                 bench          5          9      0.819      0.509      0.627      0.365\n",
            "                  bird          2         16      0.919      0.708      0.879      0.535\n",
            "                   cat          4          4      0.874          1      0.995      0.803\n",
            "                   dog          9          9       0.65      0.889      0.802      0.607\n",
            "                 horse          1          2      0.535          1      0.995      0.506\n",
            "              elephant          4         17      0.929      0.765        0.9      0.686\n",
            "                  bear          1          1      0.615          1      0.995      0.995\n",
            "                 zebra          2          4      0.854          1      0.995      0.965\n",
            "               giraffe          4          9      0.814          1      0.973      0.713\n",
            "              backpack          4          6      0.596      0.333      0.377      0.232\n",
            "              umbrella          4         18      0.736      0.465      0.651      0.432\n",
            "               handbag          9         19      0.524     0.0602      0.181     0.0994\n",
            "                   tie          6          7       0.71      0.702      0.641      0.485\n",
            "              suitcase          2          4      0.631      0.866      0.828      0.592\n",
            "               frisbee          5          5      0.628        0.8      0.759      0.688\n",
            "                  skis          1          1      0.618          1      0.995      0.497\n",
            "             snowboard          2          7      0.753      0.714      0.745        0.5\n",
            "           sports ball          6          6      0.702      0.405      0.493      0.285\n",
            "                  kite          2         10      0.802      0.407      0.563      0.183\n",
            "          baseball bat          4          4      0.594      0.391      0.414      0.199\n",
            "        baseball glove          4          7      0.677      0.429      0.429      0.273\n",
            "            skateboard          3          5      0.786        0.6        0.6      0.427\n",
            "         tennis racket          5          7      0.725      0.386      0.502      0.366\n",
            "                bottle          6         18      0.532      0.389      0.396      0.237\n",
            "            wine glass          5         16      0.874      0.434      0.601      0.338\n",
            "                   cup         10         36      0.613       0.25        0.4      0.283\n",
            "                  fork          6          6      0.569      0.167      0.292      0.204\n",
            "                 knife          7         16      0.706        0.5      0.632      0.372\n",
            "                 spoon          5         22       0.53      0.206       0.33      0.188\n",
            "                  bowl          9         28      0.619      0.581      0.615      0.492\n",
            "                banana          1          1          0          0      0.166     0.0452\n",
            "              sandwich          2          2      0.308        0.5       0.39       0.39\n",
            "                orange          1          4          1      0.316      0.995      0.666\n",
            "              broccoli          4         11      0.432      0.182      0.248      0.209\n",
            "                carrot          3         24      0.675      0.375       0.62      0.391\n",
            "               hot dog          1          2      0.353        0.5      0.745      0.721\n",
            "                 pizza          5          5      0.673          1      0.995      0.832\n",
            "                 donut          2         14      0.653          1       0.94      0.867\n",
            "                  cake          4          4      0.755          1      0.995       0.88\n",
            "                 chair          9         35      0.492      0.486      0.435       0.25\n",
            "                 couch          5          6      0.518      0.333      0.638      0.468\n",
            "          potted plant          9         14      0.743      0.621      0.722      0.477\n",
            "                   bed          3          3      0.731      0.667      0.747      0.606\n",
            "          dining table         10         13       0.44      0.615      0.505      0.409\n",
            "                toilet          2          2      0.628        0.5      0.695      0.676\n",
            "                    tv          2          2      0.382        0.5      0.745      0.696\n",
            "                laptop          2          3          1          0      0.511      0.403\n",
            "                 mouse          2          2          1          0     0.0424    0.00424\n",
            "                remote          5          8      0.863        0.5       0.58      0.499\n",
            "            cell phone          5          8          0          0     0.0575     0.0424\n",
            "             microwave          3          3      0.529      0.667       0.83      0.733\n",
            "                  oven          5          5      0.383        0.4       0.34      0.271\n",
            "                  sink          4          6      0.341      0.167      0.195      0.133\n",
            "          refrigerator          5          5      0.544        0.4      0.593      0.472\n",
            "                  book          6         29        0.6      0.103      0.323      0.175\n",
            "                 clock          8          9      0.782        0.8       0.89      0.752\n",
            "                  vase          2          2      0.379          1      0.828      0.795\n",
            "              scissors          1          1          1          0      0.249      0.079\n",
            "            teddy bear          6         21      0.877      0.333      0.617      0.413\n",
            "            toothbrush          2          5      0.681      0.435      0.699      0.421\n",
            "Speed: 10.0ms preprocess, 261.7ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 笆―n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 笆―n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 笆―n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 笆―n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 笆―n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 笆―n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 笆―n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 笆―n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 笆―n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 笆―n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 笆―n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 笆―n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 笆―n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 笆―n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 笆―n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 笆―n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.61396\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.45507\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.65732\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.52449\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 8.858\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 3157200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 261.699\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.13043\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.47437\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.26066\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.08505\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 1.12482\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.12526\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20241023_122816-gfwo1h3a\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20241023_122816-gfwo1h3a/logs\u001b[0m\n",
            "汳｡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade ultralytics supervision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Doi6yHcZGyKA",
        "outputId": "583a4334-5811-476b-aeb9-ca4c21391612"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.20)\n",
            "Requirement already satisfied: supervision in /usr/local/lib/python3.10/dist-packages (0.24.0)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.9)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "def detect_smoking(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Gagal membaca gambar {image_path}\")\n",
        "\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Run inference\n",
        "    results = model(image_rgb)[0]  # Get only the first result\n",
        "\n",
        "    # Initialize counters\n",
        "    total_smoking = 0\n",
        "    total_non_smoking = 0\n",
        "\n",
        "    # Copy image for annotation\n",
        "    annotated_image = image_rgb.copy()\n",
        "\n",
        "    # Process each detection\n",
        "    for box in results.boxes:\n",
        "        # Get box coordinates\n",
        "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "\n",
        "        # Get class_id and confidence\n",
        "        class_id = int(box.cls.cpu().numpy()[0])\n",
        "        conf = float(box.conf.cpu().numpy()[0])\n",
        "\n",
        "        # Assuming class_id for 'person' is 0, and detecting smoking based on specific logic (manual or additional models)\n",
        "        if class_id == 0:\n",
        "            # Logic for identifying smokers (e.g., based on position of hands, presence of cigarette-like objects)\n",
        "            # This can be implemented with an additional classifier or feature detection for smoking.\n",
        "            if is_smoking(box):  # You need to define is_smoking() function\n",
        "                total_smoking += 1\n",
        "                cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red for smokers\n",
        "                cv2.putText(annotated_image, f'Smoking {conf:.2f}',\n",
        "                            (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "            else:\n",
        "                total_non_smoking += 1\n",
        "                cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green for non-smokers\n",
        "                cv2.putText(annotated_image, f'Non-Smoking {conf:.2f}',\n",
        "                            (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Add statistics to the image\n",
        "    cv2.putText(annotated_image, f\"Smoking: {total_smoking}\", (10, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "    cv2.putText(annotated_image, f\"Non-Smoking: {total_non_smoking}\", (10, 70),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "    cv2.putText(annotated_image, f\"Total Persons: {total_smoking + total_non_smoking}\", (10, 110),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    return image_rgb, annotated_image, total_smoking, total_non_smoking\n",
        "\n",
        "def display_results(original_image, annotated_image, total_smoking, total_non_smoking):\n",
        "    # Create a figure with two subplots side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "    # Display original image\n",
        "    ax1.imshow(original_image)\n",
        "    ax1.set_title(\"Original\")\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Display annotated image\n",
        "    ax2.imshow(annotated_image)\n",
        "    ax2.set_title(\"Deteksi Orang Merokok\")\n",
        "    ax2.axis('off')\n",
        "\n",
        "    # Add overall title with statistics\n",
        "    plt.suptitle(f\"Deteksi Merokok\\nTotal Merokok: {total_smoking}, Tidak Merokok: {total_non_smoking}, Total: {total_smoking + total_non_smoking}\", fontsize=16)\n",
        "\n",
        "    # Adjust layout and display the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Image path\n",
        "    image_path = '/content/drive/MyDrive/data'\n",
        "\n",
        "    try:\n",
        "        # Process detection\n",
        "        original_image, annotated_image, total_smoking, total_non_smoking = detect_smoking(image_path)\n",
        "\n",
        "        # Display results\n",
        "        display_results(original_image, annotated_image, total_smoking, total_non_smoking)\n",
        "\n",
        "        # Print detection results\n",
        "        print(\"\\nHasil Deteksi:\")\n",
        "        print(f\"Total Merokok: {total_smoking}\")\n",
        "        print(f\"Total Tidak Merokok: {total_non_smoking}\")\n",
        "        print(f\"Total Orang: {total_smoking + total_non_smoking}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in processing the image: {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1p_dYNQSJDN",
        "outputId": "f22d06e6-ddb9-4f6c-c588-226104ca5e11"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in processing the image: Gagal membaca gambar /content/drive/MyDrive/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Placeholder function for determining if a person is smoking\n",
        "def is_smoking(box):\n",
        "    \"\"\"\n",
        "    Placeholder function to determine if a detected person is smoking.\n",
        "    Currently, this function returns False for demonstration purposes.\n",
        "    You can modify this to include actual smoking detection logic.\n",
        "    \"\"\"\n",
        "    # Here you can add logic to detect smoking, such as hand position, object detection (cigarette), etc.\n",
        "    return False  # Modify this logic as needed\n",
        "\n",
        "def detect_smoking(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Gagal membaca gambar {image_path}\")\n",
        "\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Run inference\n",
        "    results = model(image_rgb)[0]  # Get only the first result\n",
        "\n",
        "    # Initialize counters\n",
        "    total_smoking = 0\n",
        "    total_non_smoking = 0\n",
        "\n",
        "    # Copy image for annotation\n",
        "    annotated_image = image_rgb.copy()\n",
        "\n",
        "    # Process each detection\n",
        "    for box in results.boxes:\n",
        "        # Get box coordinates\n",
        "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "\n",
        "        # Get class_id and confidence\n",
        "        class_id = int(box.cls.cpu().numpy()[0])\n",
        "        conf = float(box.conf.cpu().numpy()[0])\n",
        "\n",
        "        # Assuming class_id for 'person' is 0, and detecting smoking based on specific logic (manual or additional models)\n",
        "        if class_id == 0:\n",
        "            if is_smoking(box):\n",
        "                total_smoking += 1\n",
        "                cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red for smokers\n",
        "                cv2.putText(annotated_image, f'Smoking {conf:.2f}',\n",
        "                            (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "            else:\n",
        "                total_non_smoking += 1\n",
        "                cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green for non-smokers\n",
        "                cv2.putText(annotated_image, f'Non-Smoking {conf:.2f}',\n",
        "                            (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Add statistics to the image\n",
        "    cv2.putText(annotated_image, f\"Smoking: {total_smoking}\", (10, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "    cv2.putText(annotated_image, f\"Non-Smoking: {total_non_smoking}\", (10, 70),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "    cv2.putText(annotated_image, f\"Total Persons: {total_smoking + total_non_smoking}\", (10, 110),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    return image_rgb, annotated_image, total_smoking, total_non_smoking\n",
        "\n",
        "def display_results(original_image, annotated_image, total_smoking, total_non_smoking):\n",
        "    # Create a figure with two subplots side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "    # Display original image\n",
        "    ax1.imshow(original_image)\n",
        "    ax1.set_title(\"Original\")\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Display annotated image\n",
        "    ax2.imshow(annotated_image)\n",
        "    ax2.set_title(\"Deteksi Orang Merokok\")\n",
        "    ax2.axis('off')\n",
        "\n",
        "    # Add overall title with statistics\n",
        "    plt.suptitle(f\"Deteksi Merokok\\nTotal Merokok: {total_smoking}, Tidak Merokok: {total_non_smoking}, Total: {total_smoking + total_non_smoking}\", fontsize=16)\n",
        "\n",
        "    # Adjust layout and display the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Image path\n",
        "    image_path = '/content/drive/MyDrive/data'\n",
        "\n",
        "    try:\n",
        "        # Process detection\n",
        "        original_image, annotated_image, total_smoking, total_non_smoking = detect_smoking(image_path)\n",
        "\n",
        "        # Display results\n",
        "        display_results(original_image, annotated_image, total_smoking, total_non_smoking)\n",
        "\n",
        "        # Print detection results\n",
        "        print(\"\\nHasil Deteksi:\")\n",
        "        print(f\"Total Merokok: {total_smoking}\")\n",
        "        print(f\"Total Tidak Merokok: {total_non_smoking}\")\n",
        "        print(f\"Total Orang: {total_smoking + total_non_smoking}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in processing the image: {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN6SqOJGasqF",
        "outputId": "2982df25-90e1-4eea-b7fa-1abd46c6127b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in processing the image: Gagal membaca gambar /content/drive/MyDrive/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = YOLO('yolov5s.pt')  # Replace with path to downloaded yolov5s.pt\n",
        "\n",
        "# Load YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "def is_smoking(box):\n",
        "    \"\"\"\n",
        "    Placeholder function to determine if a detected person is smoking.\n",
        "    \"\"\"\n",
        "    return False  # Modify this logic as needed\n",
        "\n",
        "def detect_smoking(image_path):\n",
        "    print(f\"Processing image: {image_path}\")\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Gagal membaca gambar {image_path}\")\n",
        "\n",
        "    print(f\"Gambar berhasil dibaca: {image.shape}\")\n",
        "\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Run inference\n",
        "    results = model(image_rgb)[0]  # Get only the first result\n",
        "    print(f\"Deteksi selesai, ditemukan {len(results.boxes)} objek.\")\n",
        "\n",
        "    # Initialize counters\n",
        "    total_smoking = 0\n",
        "    total_non_smoking = 0\n",
        "\n",
        "    # Copy image for annotation\n",
        "    annotated_image = image_rgb.copy()\n",
        "\n",
        "    # Process each detection\n",
        "    for box in results.boxes:\n",
        "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "\n",
        "        class_id = int(box.cls.cpu().numpy()[0])\n",
        "        conf = float(box.conf.cpu().numpy()[0])\n",
        "\n",
        "        # Assuming class_id for 'person' is 0\n",
        "        if class_id == 0:\n",
        "            if is_smoking(box):\n",
        "                total_smoking += 1\n",
        "                cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "                cv2.putText(annotated_image, f'Smoking {conf:.2f}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "            else:\n",
        "                total_non_smoking += 1\n",
        "                cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                cv2.putText(annotated_image, f'Non-Smoking {conf:.2f}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Add statistics to the image\n",
        "    cv2.putText(annotated_image, f\"Smoking: {total_smoking}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "    cv2.putText(annotated_image, f\"Non-Smoking: {total_non_smoking}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "    cv2.putText(annotated_image, f\"Total Persons: {total_smoking + total_non_smoking}\", (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    return image_rgb, annotated_image, total_smoking, total_non_smoking\n",
        "\n",
        "def display_results(original_image, annotated_image, total_smoking, total_non_smoking):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "    ax1.imshow(original_image)\n",
        "    ax1.set_title(\"Original\")\n",
        "    ax1.axis('off')\n",
        "\n",
        "    ax2.imshow(annotated_image)\n",
        "    ax2.set_title(\"Deteksi Orang Merokok\")\n",
        "    ax2.axis('off')\n",
        "\n",
        "    plt.suptitle(f\"Deteksi Merokok\\nTotal Merokok: {total_smoking}, Tidak Merokok: {total_non_smoking}, Total: {total_smoking + total_non_smoking}\", fontsize=16)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Image path\n",
        "    image_path = '/content/drive/MyDrive/data/'\n",
        "\n",
        "    try:\n",
        "        original_image, annotated_image, total_smoking, total_non_smoking = detect_smoking(image_path)\n",
        "        print(\"Menampilkan hasil deteksi...\")\n",
        "        display_results(original_image, annotated_image, total_smoking, total_non_smoking)\n",
        "        print(f\"\\nHasil Deteksi:\\nTotal Merokok: {total_smoking}\\nTotal Tidak Merokok: {total_non_smoking}\\nTotal Orang: {total_smoking + total_non_smoking}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in processing the image: {str(e)}\")\n",
        "        raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "2k2ZoASr-HAK",
        "outputId": "fe1df96e-aa9d-4de2-c382-f395e296c22e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRO TIP 汳｡ Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "Processing image: /content/drive/MyDrive/data/\n",
            "Error in processing the image: Gagal membaca gambar /content/drive/MyDrive/data/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Gagal membaca gambar /content/drive/MyDrive/data/",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-bbefa406da50>\u001b[0m in \u001b[0;36m<cell line: 83>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0moriginal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotated_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_smoking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_non_smoking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_smoking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Menampilkan hasil deteksi...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mdisplay_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotated_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_smoking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_non_smoking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-bbefa406da50>\u001b[0m in \u001b[0;36mdetect_smoking\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Gagal membaca gambar {image_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Gambar berhasil dibaca: {image.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Gagal membaca gambar /content/drive/MyDrive/data/"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Load model\n",
        "model = YOLO('yolov5s.pt')  # Ganti dengan path model Anda\n",
        "\n",
        "# Fungsi untuk memproses gambar dan menghitung jumlah rokok\n",
        "def count_cigarettes(image_path):\n",
        "    # Load gambar\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # Prediksi\n",
        "    results = model(img)\n",
        "\n",
        "    # Inisialisasi DataFrame untuk menyimpan hasil\n",
        "    data = []\n",
        "\n",
        "    # Iterasi melalui setiap deteksi\n",
        "    for *xyxy, conf, cls in results.xyxy[0]:\n",
        "        # Konversi koordinat ke integer\n",
        "        x1, y1, x2, y2 = int(xyxy[0]), int(xyxy[1]), int(xyxy[2]), int(xyxy[3])\n",
        "        # Dapatkan nama kelas dari indeks kelas\n",
        "        cls = int(cls)\n",
        "        # Tambahkan data ke list\n",
        "        data.append([x1, y1, x2, y2, cls])\n",
        "\n",
        "    # Buat DataFrame Pandas\n",
        "    #results_df = pd.DataFrame(data, columns=['xmin', 'ymin', 'xmax', 'ymax', 'class'])\n",
        "\n",
        "    # Konversi hasil ke DataFrame Pandas\n",
        "    results_df = pd.DataFrame.from_dict(results.pandas().xyxy[0])\n",
        "\n",
        "    # Hitung jumlah rokok untuk setiap merek\n",
        "    counts = results_df['class'].value_counts()\n",
        "\n",
        "\n",
        "    # Visualisasi hasil\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(img[:, :, ::-1])  # BGR to RGB\n",
        "    for _, row in results_df.iterrows():\n",
        "        x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(img, row['name'], (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    return counts\n",
        "\n",
        "image_path = '/content/drive/MyDrive/PCVK/Cigarettes.jpg'\n",
        "cigarette_counts = count_cigarettes(image_path)\n",
        "print(cigarette_counts)\n",
        "\n",
        "# Simpan hasil ke file CSV\n",
        "cigarette_counts.to_csv('cigarette_counts.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "vyIq70PjNK86",
        "outputId": "dd32891b-52a2-4b4e-e33d-de3826c1be17"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRO TIP 汳｡ Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "\n",
            "0: 640x480 2 books, 742.4ms\n",
            "Speed: 4.7ms preprocess, 742.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'xyxy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-838d8925ae91>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/PCVK/Cigarettes.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mcigarette_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_cigarettes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcigarette_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-838d8925ae91>\u001b[0m in \u001b[0;36mcount_cigarettes\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Iterasi melalui setiap deteksi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Konversi koordinat ke integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'xyxy'"
          ]
        }
      ]
    }
  ]
}